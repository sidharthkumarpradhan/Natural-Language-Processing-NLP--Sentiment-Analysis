{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data_Preprocessing.ipynb\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from torchtext.data import Field, LabelField, TabularDataset, BucketIterator\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/sentiment_dataset.csv')\n",
    "\n",
    "# Tokenization and preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Save the preprocessed data\n",
    "df.to_csv('data/preprocessed_sentiment_dataset.csv', index=False)\n",
    "\n",
    "# Define TorchText fields\n",
    "TEXT = Field(tokenize='spacy', include_lengths=True)\n",
    "LABEL = LabelField(dtype=torch.float)\n",
    "\n",
    "# Load preprocessed data into TorchText TabularDataset\n",
    "data_fields = [('text', TEXT), ('label', LABEL)]\n",
    "train_data, valid_data, test_data = TabularDataset.splits(\n",
    "    path='data/',\n",
    "    train='preprocessed_sentiment_dataset.csv',\n",
    "    validation='preprocessed_sentiment_dataset.csv',\n",
    "    test='preprocessed_sentiment_dataset.csv',\n",
    "    format='csv',\n",
    "    fields=data_fields\n",
    ")\n",
    "\n",
    "# Build vocabulary and create iterators\n",
    "TEXT.build_vocab(train_data, max_size=25000, vectors='glove.6B.100d', unk_init=torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    datasets=(train_data, valid_data, test_data),\n",
    "    batch_size=64,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    device=device\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
